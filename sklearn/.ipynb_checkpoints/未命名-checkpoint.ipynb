{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.5]\n",
      "[1.4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# 线性回归\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "# fit\n",
    "reg.fit([[0, 0], [1, 1], [2, 2]], [0, 1, 2])\n",
    "\n",
    "# 权重\n",
    "print(reg.coef_)\n",
    "\n",
    "# pred\n",
    "pred = reg.predict([[0.5, 2.3]])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44444444 0.44444444]\n",
      "[1.35555556]\n"
     ]
    }
   ],
   "source": [
    "# 岭回归（Rige reg)\n",
    "reg = linear_model.Ridge(alpha=0.5)\n",
    "\n",
    "# fit\n",
    "reg.fit([[0, 0], [1, 1], [2, 2]], [0, 1, 2])\n",
    "\n",
    "# 权重\n",
    "print(reg.coef_)\n",
    "\n",
    "# pred\n",
    "pred = reg.predict([[0.5, 2.3]])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25 0.  ]\n",
      "[0.875]\n"
     ]
    }
   ],
   "source": [
    "# Lasso回归\n",
    "reg = linear_model.Lasso(alpha=0.5)\n",
    "\n",
    "# fit\n",
    "reg.fit([[0, 0], [1, 1], [2, 2]], [0, 1, 2])\n",
    "\n",
    "# 权重\n",
    "print(reg.coef_)\n",
    "\n",
    "# pred\n",
    "pred = reg.predict([[0.5, 2.3]])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逻辑回归（对数几率回归）\n",
    "```python\n",
    "class sklearn.linear_model.LogisticRegression(penalty='l2', \n",
    "          dual=False, tol=0.0001, C=1.0, fit_intercept=True, \n",
    "          intercept_scaling=1, class_weight=None, \n",
    "          random_state=None, solver='liblinear', max_iter=100, \n",
    "          multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "```\n",
    "**penalty='l2'** : 字符串‘l1’或‘l2’,默认‘l2’。\n",
    "用来指定惩罚的基准（正则化参数）。只有‘l2’支持‘newton-cg’、‘sag’和‘lbfgs’这三种算法。\n",
    "如果选择‘l2’，solver参数可以选择‘liblinear’、‘newton-cg’、‘sag’和‘lbfgs’这四种算法；\n",
    "\n",
    "如果选择‘l1’的话就只能用‘liblinear’算法。\n",
    "\n",
    "**dual=False** : 对偶或者原始方法。Dual只适用于正则化相为l2的‘liblinear’的情况，通常样本数大于特征数的情况下，默认为False。\n",
    "\n",
    "**C=1.0** : C为正则化系数λ的倒数，必须为正数，默认为1。和SVM中的C一样，值越小，代表正则化越强。\n",
    "\n",
    "**fit_intercept=True** : 是否存在截距，默认存在。\n",
    "**intercept_scaling=1** : 仅在正则化项为‘liblinear’，且fit_intercept设置为True时有用。\n",
    "**solver='liblinear'** : \n",
    ">solver参数决定了对逻辑回归损失函数的优化方法，有四种算法可以选择。\n",
    "a) liblinear：使用了开源的liblinear库实现，内部使用了坐标轴下降法来迭代优化损失函数。\n",
    "b) lbfgs：拟牛顿法的一种，利用损失函数二阶导数矩阵即海森矩阵来迭代优化损失函数。\n",
    "c) newton-cg：也是牛顿法家族的一种，利用损失函数二阶导数矩阵即海森矩阵来迭代优化损失函数。\n",
    "d) sag：即随机平均梯度下降，是梯度下降法的变种，和普通梯度下降法的区别是每次迭代仅仅用一部分的样本来计算梯度，适合于样本数据多的时候。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25 0.  ]\n",
      "[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.66667091, 0.33332909]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 逻辑回归\n",
    "log_reg = linear_model.LogisticRegression(penalty='l2',\n",
    "                                         C=1.0,\n",
    "                                         solver='lbfgs')\n",
    "log_reg.fit([[1,1],[2,2],[3,3]],[0,1,0])\n",
    "\n",
    "# 权重\n",
    "print(reg.coef_)\n",
    "\n",
    "# 预测\n",
    "pred = log_reg.predict([[0.5, 2.3]])\n",
    "print(pred)\n",
    "# 输出分类概率\n",
    "log_reg.predict_proba([[0.5,2.3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性判别模型（LDA）\n",
    "```python\n",
    "class sklearn.discriminant_analysis.LinearDiscriminantAnalysis(*,\n",
    "                                                               solver='svd', \n",
    "                                                               shrinkage=None, \n",
    "                                                               priors=None, \n",
    "                                                               n_components=None,\n",
    "                                                               store_covariance=False, \n",
    "                                                               tol=0.0001)\n",
    "```\n",
    "**solver**:求LDA超平面特征矩阵使用的方法，可以选择的方法有奇异值分解\"svd\"、最小二乘\"lsqr\"和特征分解\"eigen\"。一般来说特征非常多的时候推荐使用\"svd\"，而特征不多的时候推荐使用\"eigen\"。需要注意的是，如果使用\"svd\"，则不能指定正则化参数shrinkage进行正则化。默认值是\"svd\"。\n",
    "\n",
    "**shrinkage**:正则化参数，可以增强LDA分类的泛化能力。如果仅仅是为了降维，则可以忽略这个参数。默认值是None，即不进行正则化。可以选择\"auto\"，让算法自己决定是否正则化。当然也可以选择不同的[0,1]之间的值进行交叉验证调参。需要注意的是，shrinkage只在solver为最小二乘\"lsqr\"和特征分解\"eigen\"时有效。\n",
    "\n",
    "**priors**:类别权重，在做分类模型时可以指定不同类别的权重，进而影响分类模型的建立。降维时一般不需要关注这个参数。\n",
    "\n",
    "**n_components**:进行LDA降维时降到的维度。在降维时需要输入这个参数。可选值只能为[1,类别数-1)范围之间的整数。如果不是用于降维，则这个值可以用默认的None。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "print(iris.keys())\n",
    "\n",
    "# 150个样本，4个特征\n",
    "data = iris.data\n",
    "label = iris.target\n",
    "\n",
    "# 数据集拆分\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "    train_test_split(data, label, test_size=0.2)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(solver='svd',\n",
    "                                 shrinkage=None,\n",
    "                                 n_components=2)\n",
    "\n",
    "lda.fit(x_train, y_train)\n",
    "print(lda.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
